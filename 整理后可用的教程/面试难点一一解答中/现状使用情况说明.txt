SLB 负责负载均衡处理
haproxy 用作多服务中转
nginx 反向代理服务
redis 缓存服务
mongo 调用日志存储和检索查询使用(订单流转过程)
mysql 存储数据
rabbitmq 做消息中间件，解决订单量大和顺序分发处理问题(解决多进程处理订单的竞争和效率问题，设计死信队列防止消息丢失问题)
openresty 基于nginx开发服务器，支持lua脚本的执行(引入了lua库)
java 开发项目
HTML静态化

==============新技术================
ES 快速检索Nosql  主要用于日志分析
kafka 日志收集存储介质，用于同步到ES的中转



==============服务搭建中================
NAS盘  解决多机数据共享(网络协议盘)
CDN    网络加速器，把静态资源上传到CDN服务器，减少资源到用户的路径长度，实现加速
OSS   阿里云存储 解决跨服务跨资源调用问题(一处上传，多处使用)


==============并发解决方案================
流量系统，订单前置，后入库，分发预占分配
短信系统，订单入队列，后入库，从队列直接分发发送
从入库+预占===》》》入队列  性能提升，问题出现
HTML静态化
漏桶(Leaky bucket)与令牌桶(Token bucket)算法的流量控制也叫过载保护





==============高并发====================
高并发（High Concurrency） 通过设计保证系统能够同时并行处理很多请求
高并发相关常用的一些指标有响应时间（Response Time），吞吐量（Throughput），每秒查询率QPS（Query Per Second），并发用户数等

响应时间：系统对请求做出响应的时间。例如系统处理一个HTTP请求需要200ms，这个200ms就是系统的响应时间。
吞吐量：单位时间内处理的请求数量。
QPS：每秒响应请求数。在互联网领域，这个指标和吞吐量区分的没有这么明显。
并发用户数：同时承载正常使用系统功能的用户数量。例如一个即时通讯系统，同时在线量一定程度上代表了系统的并发用户数。

--------------------------------
提升系统的并发能力
垂直扩展（Scale Up）与水平扩展（Scale Out）
垂直扩展：提升单机处理能力。垂直扩展的方式又有两种：
（1）增强单机硬件性能，例如：增加CPU核数如32核，升级更好的网卡如万兆，升级更好的硬盘如SSD，扩充硬盘容量如2T，扩充系统内存如128G；
（2）提升单机架构性能，例如：使用Cache来减少IO次数，使用异步来增加单服务吞吐量，使用无锁数据结构来减少响应时间；

水平扩展：只要增加服务器数量，就能线性扩充系统性能。水平扩展对系统架构设计是有要求的，如何在架构各层进行可水平扩展的设计，以及互联网公司架构各层常见的水平扩展实践，是本文重点讨论的内容。

DNS解析到多台SLB < DNS轮询 >
SLB负载到多台nginx
nginx反向代理到多台服务
服务访问多台缓存+数据库    服务层的水平扩展，是通过“服务连接池”实现的 
缓存 redis实现(哨兵+多台master>slave>slave) 数据库多台(master>slave)
RPC 服务访问方式


（1）反向代理层可以通过“DNS轮询”的方式来进行水平扩展；
（2）站点层可以通过nginx来进行水平扩展；
（3）服务层可以通过服务连接池来进行水平扩展；
（4）数据库可以按照数据范围，或者数据哈希的方式来进行水平扩展；


--------------------指标--------------------
QPS：每秒钟查询量，广义的，通常指指每秒请求数
响应时间：从请求发出到收到响应花费的时间，例如：系统处理一个HTTP请求需要100ms，这个100ms就是系统的响应时间
带宽：计算带宽大小需关注两个指标，峰值流量和页面的平均大小 
PV：综合浏览量(Page View)，即页面浏览量或者点击量，通常关注在24小时内访问的页面数量，即“日PV”
UV：独立访问(UniQue Visitor)，即去重后的访问用户数，通常关注在24小时内访问的用户，即“日UV”





=====================高可用HA=====================
高可用HA（High Availability）是分布式系统架构设计中必须考虑的因素之一，它通常是指，通过设计减少系统不能提供服务的时间

高可用保证的原则是“集群化”，或者叫“冗余”
保证系统高可用，架构设计的核心准则是：冗余。
“自动故障转移”来实现系统的高可用

双活方案
keepalived存活探测，相同virtual IP提供服务
自动故障转移：当nginx挂了的时候，keepalived能够探测到，会自动的进行故障转移，将流量自动迁移到shadow-nginx，由于使用的是相同的virtual IP，这个切换过程对调用方是透明的。

nginx 挂多服务进行服务可用检测实现高可用

“服务连接池”会建立与下游服务多个连接
service对cache进行双读或者双写
将kv缓存封装成服务集群，上游设置一个代理

数据库层都用了“主从同步，读写分离”架构
“读库高可用”与“写库高可用”两类
至少有2个从库，“数据库连接池”会建立与读库多个连接
设置两个mysql双主同步，一台对线上提供服务，另一台冗余以保证高可用，常见的实践是keepalived存活探测，相同virtual IP提供服务

--------------------方案--------------------
通过每一层的冗余+自动故障转移来综合实现的
（1）【客户端层】到【反向代理层】的高可用，是通过反向代理层的冗余实现的，常见实践是keepalived + virtual IP自动故障转移

（2）【反向代理层】到【站点层】的高可用，是通过站点层的冗余实现的，常见实践是nginx与web-server之间的存活性探测与自动故障转移

（3）【站点层】到【服务层】的高可用，是通过服务层的冗余实现的，常见实践是通过service-connection-pool来保证自动故障转移

（4）【服务层】到【缓存层】的高可用，是通过缓存数据的冗余实现的，常见实践是缓存客户端双读双写，或者利用缓存集群的主从数据同步与sentinel保活与自动故障转移；更多的业务场景，对缓存没有高可用要求，可以使用缓存服务化来对调用方屏蔽底层复杂性

（5）【服务层】到【数据库“读”】的高可用，是通过读库的冗余实现的，常见实践是通过db-connection-pool来保证自动故障转移

（6）【服务层】到【数据库“写”】的高可用，是通过写库的冗余实现的，常见实践是keepalived + virtual IP自动故障转移



========================容量设计=========================
容量设计是架构师必备的技能之一
【步骤一：评估总访问量】 -> 询问业务、产品、运营

【步骤二：评估平均访问量QPS】-> 除以时间，一天算4w秒

【步骤三：评估高峰QPS】 -> 根据业务曲线图来

【步骤四：评估系统、单机极限QPS】 -> 压测很重要

【步骤五：根据线上冗余度回答两个问题】 -> 估计冗余度与线上冗余度差值




======================超高并发的无锁缓存======================
超高并发的无锁缓存
在【超高并发】，【写多读少】，【定长value】的【业务缓存】场景下：

1）可以通过水平拆分来降低锁冲突

2）可以通过Map转Array的方式来最小化锁冲突，一条记录一个锁

3）可以把锁去掉，最大化并发，但带来的数据完整性的破坏

4）可以通过签名的方式保证数据的完整性，实现无锁缓存


多事务优化
trx1.exec();
trx1.commit();
trx2.exec();
trx2.commit();
trx3.exec();
trx3.commit();

优化为：
trx1.exec();
trx2.exec();
trx3.exec();
trx1.commit();
trx2.commit();
trx3.commit();

这个小小的改动（改动成本极低），不能彻底解决多库分布式事务数据一致性问题，但能大大降低数据不一致的概率，带来的副作用是数据库连接占用时间会增长，吞吐量会降低。对于一致性与吞吐量的折衷，还需要业务架构师谨慎权衡折衷。


线程数设置
非CPU密集型的业务（加解密、压缩解压缩、搜索排序等业务是CPU密集型的业务），瓶颈都在后端数据库，本地CPU计算的时间很少，所以设置几十或者几百个工作线程也都是可能的。
N核服务器，通过执行业务的单线程分析出本地计算时间为x，等待时间为y，则工作线程数（线程池线程数）设置为 N*(x+y)/x，能让CPU的利用率最大化





