Hive是一个架构在Hadoop之上的数据仓库基础工具，用来处理结构化数据，为大数据查询和分析提供方便

Hive就是在Hadoop上架了一层SQL接口，可以将SQL翻译成MapReduce去Hadoop上执行，这样就使得数据开发和分析人员很方便的使用SQL来完成海量数据的统计和分析，而不必使用编程语言开发MapReduce那么麻烦


Hive 数据仓库，通过使用HiveQL,方便使用类似SQL的语句进行对表的管理，支持离散数据处理

Hive 底层使用MapReduce 进行计算
Hive支持三种连接表的方式，map join ,reduce join 和semi join
map join 使用的条件是左表数据量较小，可以直接放到内存中，那么右表与左表的数据进行一一的比对。
reduce join 就是对map的结果进行运算，因为存在多个map的结果，所以运算量很大，网络上的传输消耗也很大。
semi join 就是在进行reduce join之前对map的结果进行筛选，筛选一些重复的key,做法是将左表随机分成一个小表，放入内存，将另一部分与他进行比较，去除重复的。


内部表 MANAGE_TABLE
表结构(元数据)和真实数据同时删除，不安全
外部表 EXTERNAL_TABLE
表结构(元数据)删除，但是真实数据保留，
可以通过创建同名表的形式恢复数据，比较安全


单分区
只有一个分区字段，在hdfs里只有一个目录层次

多分区
有多个字段同时作为分区条件，在hdfs上有多个目录层次
partition (分区字段=xxx)


分桶
把数据按照文件级别进行随机划分，对已有的数据进行分桶
分桶也要指定字段(表中的字段)，必须指定桶数
创建一个分桶表，把原有表数据加载到分桶表中使用
原理：分桶字段的hashCode值对桶数取余，余数为当前数据所在桶
clustered by (分桶字段)
into n buckets


Hive是建立在Hadoop上的数据仓库基础架构。它提供了一系列的工具，用来进行数据提取、转换、加载，这是一种可以存储、查询和分析存储在Hadoop中的大规模数据机制。可以把Hadoop下结构化数据文件映射为一张成Hive中的表，并提供类sql查询功能，除了不支持更新、索引和事务，sql其它功能都支持。
Hive的数据管理按照使用层次可以从元数据存储、数据存储和数据交换三个方面介绍。

Hive中所有的数据都存储在HDFS中，Hive中包含4中数据模型：Tabel、ExternalTable、Partition、Bucket。
Hive数据中的列分隔符和行分隔符

ExternalTable指向已存在HDFS中的数据，可创建Partition。


